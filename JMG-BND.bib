%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jose Marcos Gomes at 2020-10-06 10:00:45 -0300 


%% Saved with string encoding Unicode (UTF-8) 



@book{10.5555/217720,
  author    = {Kit, Edward and Finzi, Susannah},
  title     = {Software Testing in the Real World: Improving the Process},
  year      = {1995},
  isbn      = {0201877562},
  publisher = {ACM Press/Addison-Wesley Publishing Co.},
  address   = {USA}
}

@article{abaei_empirical_2015,
  abstract     = {*We proposed a software fault detection model using semi-supervised hybrid self-organizing map ({HySOM}).*The {HySOM} minimize the role of experts for identifying fault prone modules.*The advantage of {HySOM} is the ability to predict the label of the modules in a semi-supervised manner.*The experimental results show improvement in false negative rate and overall error rate in 80\% and 60\% with {NASA} data sets. Software testing is a crucial task during software development process with the potential to save time and budget by recognizing defects as early as possible and delivering a more defect-free product. To improve the testing process, fault prediction approaches identify parts of the system that are more defect prone. However, when the defect data or quality-based class labels are not identified or the company does not have similar or earlier versions of the software project, researchers cannot use supervised classification methods for defect detection. In order...},
  author       = {Abaei, Golnoush and Selamat, Ali and Fujita, Hamido},
  date         = {2015},
  doi          = {10.1016/j.knosys.2014.10.017},
  file         = {Full Text:/Users/marcos/Zotero/storage/W2A334RZ/Abaei et al. - 2015 - An empirical study based on semi-supervised hybrid.pdf:application/pdf},
  issn         = {0950-7051},
  journaltitle = {Knowledge-based systems},
  keywords     = {Computer Science, Artificial Neural Network, Clustering, Self-Organizing Maps, Semi-Supervised, Software Fault Prediction, Threshold},
  pages        = {28--39},
  title        = {An empirical study based on semi-supervised hybrid self-organizing map for software fault prediction},
  volume       = {74},
  bdsk-url-1   = {https://doi.org/10.1016/j.knosys.2014.10.017}
}
@article{abdi_hybrid_2015,
  abstract     = {Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization ({DSMOPSO}). Because of discrete search space, we modified this algorithm and named it {DSMOPSO}-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the {PROMISE} repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets.},
  author       = {Abdi, Yousef and Parsa, Saeed and Seyfari, Yousef},
  date         = {2015},
  doi          = {10.1007/s11334-015-0258-2},
  file         = {Full Text:/Users/marcos/Zotero/storage/3XKARCIC/Abdi et al. - 2015 - A hybrid one-class rule learning approach based on.pdf:application/pdf},
  issn         = {1614-5046},
  journaltitle = {Innovations in Systems and Software Engineering},
  keywords     = {Classification rules, {DSMOPSO}-D, Fault prediction, Imbalanced data sets, Kernel k-means, Multi-objective particle swarm optimization},
  number       = {4},
  pages        = {289--301},
  shortjournal = {Innovations Syst Softw Eng},
  title        = {A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction},
  volume       = {11},
  bdsk-url-1   = {https://doi.org/10.1007/s11334-015-0258-2}
}
@article{almaghairbe_separating_2017,
  abstract     = {Developments in the automation of test data generation have greatly improved efficiency of the software testing process, but the so-called oracle problem (deciding the pass or fail outcome of a test execution) is still primarily an expensive and error-prone manual activity. We present an approach to automatically detect passing and failing executions using cluster-based anomaly detection on dynamic execution data based on firstly, just a system's input/output pairs and secondly, amalgamations of input/output pairs and execution traces. The key hypothesis is that failures will group into small clusters, whereas passing executions will group into larger ones. Evaluation on three systems with a range of faults demonstrates this hypothesis to be valid--in many cases small clusters were composed of at least 60 \% failures (and often more). Concentrating the failures in these small clusters substantially reduces the numbers of outputs that a developer would need to manually examine following a...},
  author       = {Almaghairbe, Rafig and Roper, Marc},
  date         = {2017},
  doi          = {10.1007/s11219-016-9339-1},
  file         = {Full Text:/Users/marcos/Zotero/storage/BU6RZ5HM/Almaghairbe and Roper - 2017 - Separating passing and failing test executions by .pdf:application/pdf},
  issn         = {09639314},
  journaltitle = {Software Quality Journal},
  keywords     = {Software Testing, Error Detection, Faults, Test Oracles, Clustering, Amalgamation, Anomalies, Anomaly Detection, Clusters, Failure, Hypotheses, Systems Analysis, Verification, Testing, and Debugging (Ci)},
  number       = {3},
  pages        = {803--840},
  title        = {Separating passing and failing test executions by clustering anomalies},
  volume       = {25},
  bdsk-url-1   = {https://doi.org/10.1007/s11219-016-9339-1}
}
@article{anwar_hybrid-adaptive_2019,
  abstract     = {Regression testing is a mandatory activity of software development life cycle, which is performed to ensure that modifications have not caused any adverse effects on the system's functionality. With every change in software in the maintenance phase, the size of regression test suite grows as new test cases are written to validate changes. The bigger size of regression test suite makes the testing expensive and time-consuming. Optimization of regression test suite is a possible solution to cope with this problem. Various techniques of optimization have been proposed},
  author       = {Anwar, Zeeshan and Afzal, Hammad and Bibi, Nazia and Abbas, Haider and Mohsin, Athar and Arif, Omar},
  date         = {2019},
  doi          = {10.1007/s00521-018-3560-8},
  file         = {Full Text:/Users/marcos/Zotero/storage/XNHBCE62/Anwar et al. - 2019 - A hybrid-adaptive neuro-fuzzy inference system for.pdf:application/pdf},
  issn         = {0941-0643},
  journaltitle = {Neural Computing and Applications},
  keywords     = {Genetic algorithm, Adaptive neuro-fuzzy inference system, Particle swarm algorithm, Regression test suite optimization},
  number       = {11},
  pages        = {7287--7301},
  shortjournal = {Neural Comput \& Applic},
  title        = {A hybrid-adaptive neuro-fuzzy inference system for multi-objective regression test suites optimization},
  volume       = {31},
  bdsk-url-1   = {https://doi.org/10.1007/s00521-018-3560-8}
}
@article{basili1984methodology,
  title     = {A methodology for collecting valid software engineering data},
  author    = {Basili, Victor R and Weiss, David M},
  journal   = {IEEE Transactions on software engineering},
  number    = {6},
  pages     = {728--738},
  year      = {1984},
  publisher = {IEEE}
}
@article{bohm1966flow,
  title     = {Flow diagrams, turing machines and languages with only two formation rules},
  author    = {B{\"o}hm, Corrado and Jacopini, Giuseppe},
  journal   = {Communications of the ACM},
  volume    = {9},
  number    = {5},
  pages     = {366--371},
  year      = {1966},
  publisher = {ACM New York, NY, USA}
}
@article{boughorbel2017optimal,
  title     = {Optimal classifier for imbalanced data using Matthews Correlation Coefficient metric},
  author    = {Boughorbel, Sabri and Jarray, Fethi and El-Anbari, Mohammed},
  journal   = {PloS one},
  volume    = {12},
  number    = {6},
  pages     = {e0177678},
  year      = {2017},
  publisher = {Public Library of Science San Francisco, CA USA}
}
@article{bowes_software_2018,
  abstract     = {During the last 10 years, hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80\% recall. We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers. We perform a sensitivity analysis to compare the performance of Random Forest, Na{\"\i}ve Bayes, {RPart} and {SVM} classifiers when predicting defects in {NASA}, open source and commercial datasets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty of each classifier is compared. Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others. Our results confirm that a unique subset of defects can be detected...},
  author       = {Bowes, David and Hall, Tracy and Petri{\'c}, Jean},
  date         = {2018},
  year         = {2018},
  doi          = {10.1007/s11219-016-9353-3},
  file         = {Full Text:/Users/marcos/Zotero/storage/2UQ7U7CW/Bowes et al. - 2018 - Software defect prediction do different classifie.pdf:application/pdf},
  issn         = {09639314},
  journaltitle = {Software Quality Journal},
  keywords     = {Uncertainty, Freeware, Mathematical Models, Machine Learning, Decision Trees, Defects, Bayesian Analysis, Classifiers, Commercial Spacecraft, Decision Making, Performance Prediction, Prediction Modelling, Sensitivity Analysis, Software Defect Prediction},
  number       = {2},
  pages        = {525--552},
  title        = {Software defect prediction: do different classifiers find the same defects?},
  volume       = {26},
  bdsk-url-1   = {https://doi.org/10.1007/s11219-016-9353-3}
}
@article{chatterjee_bayesian_2018,
  abstract     = {It is always better to have an idea about the future situation of a present work. Prediction of software faults in the early phase of software development life cycle can facilitate to the software personnel to achieve their desired software product. Early prediction is of great importance for optimizing the development cost of a software project. The present study proposes a methodology based on Bayesian belief network, developed to predict total number of faults and to reach a target value of total number of faults during early development phase of software lifecycle. The model has been carried out using the information from similar or earlier version software projects, domain expert's opinion and the software metrics. Interval type-2 fuzzy logic has been applied for obtaining the conditional probability values in the node probability tables of the belief network. The output pattern corresponding to the total number of faults has been identified by artificial neural network using the input pattern from similar or earlier project data. The proposed Bayesian framework facilitates software personnel to gain the required information about software metrics at early phase for achieving targeted number of software faults. The proposed model has been applied on twenty six software project data. Results have been validated by different statistical comparison criterion. The performance of the proposed approach has been compared with some existing early fault prediction models.},
  author       = {Chatterjee, Subhashis and Maji, Bappa},
  date         = {2018},
  doi          = {10.1007/s10489-017-1078-x},
  file         = {Full Text:/Users/marcos/Zotero/storage/XHIK4NRK/Chatterjee and Maji - 2018 - A bayesian belief network based model for predicti.pdf:application/pdf},
  issn         = {0924-669X},
  journaltitle = {Applied Intelligence},
  keywords     = {Software metrics, Artificial neural network, Bayesian belief network, Early fault prediction, Interval type-2 fuzzy control system},
  number       = {8},
  pages        = {2214--2228},
  shortjournal = {Appl Intell},
  title        = {A bayesian belief network based model for predicting software faults in early phase of software development process},
  volume       = {48},
  bdsk-url-1   = {https://doi.org/10.1007/s10489-017-1078-x}
}
@inproceedings{chinchor-1992-muc,
  title     = {{MUC}-4 Evaluation Metrics},
  author    = {Chinchor, Nancy},
  booktitle = {{F}ourth {M}essage {U}understanding {C}onference ({MUC}-4): Proceedings of a Conference Held in {M}c{L}ean, {V}irginia, {J}une 16-18, 1992},
  year      = {1992},
  url       = {https://www.aclweb.org/anthology/M92-1002}
}
@article{dhanalaxmi_adaptive_2015,
  abstract     = {The proposed system categorizes various defects by using association rule mining dependent problem classification approach, which is applied to collect the actual defects using recognition. Association rule mining algorithm at times results in useless policies. To avoid this kind of concerns, the principles prior to classification determined by assistance as well as confidence value has to be optimized. In this exploration, Adaptive Particle Swarm ({APSO}) optimization algorithm is used. This can discover the best assistance and confidence value to have the best policies. And finally Artificial Neural Network ({ANN}) can be used to classify the actual defects determined.},
  author       = {Dhanalaxmi, B and Naidu, G. Apparao and Anuradha, K},
  date         = {2015},
  doi          = {10.1016/j.procs.2015.02.041},
  file         = {Full Text:/Users/marcos/Zotero/storage/5GRWW6UQ/Dhanalaxmi et al. - 2015 - Adaptive PSO Based Association Rule Mining Techniq.pdf:application/pdf},
  issn         = {1877-0509},
  issue        = {C},
  journaltitle = {Procedia computer science},
  keywords     = {Software Testing, Computer Science, Artificial Neural Network, Adaptive Particle Swarm Optimization Algorithm, Association Rule Mining, Defect Prevention},
  pages        = {432--442},
  title        = {Adaptive {PSO} Based Association Rule Mining Technique for Software Defect Classification Using {ANN}
},
  volume       = {46},
  bdsk-url-1   = {https://doi.org/10.1016/j.procs.2015.02.041}
}
@article{diwaker_prediction_2018,
  abstract     = {A lot of models have been made for predicting software reliability. The reliability models are restricted to using particular types of methodologies and restricted number of parameters. There are a number of techniques and methodologies that may be used for reliability prediction. There is need to focus on parameters consideration while estimating reliability. The reliability of a system may increase or decreases depending on the selection of different parameters used. Thus there is need to identify factors that heavily affecting the reliability of the system. In present days, reusability is mostly used in the various area of research. Reusability is the basis of Component-Based System ({CBS}). The cost, time and human skill can be saved using Component-Based Software Engineering ({CBSE}) concepts. {CBSE} metrics may be used to assess those techniques which are more suitable for estimating system reliability. Soft computing is used for small as well as large-scale problems where it is difficult to find accurate results due to uncertainty or randomness. Several possibilities are available to apply soft computing techniques in medicine related problems. Clinical science of medicine using fuzzy-logic, neural network methodology significantly while basic science of medicine using neural-networks-genetic algorithm most frequently and preferably. There is unavoidable interest shown by medical scientists to use the various soft computing methodologies in genetics, physiology, radiology, cardiology and neurology discipline. {CBSE} boost users to reuse the past and existing software for making new products to provide quality with a saving of time, memory space, and money. This paper focused on assessment of commonly used soft computing technique like Genetic Algorithm ({GA}), Neural-Network ({NN}), Fuzzy Logic, Support Vector Machine ({SVM}), Ant Colony Optimization ({ACO}), Particle Swarm Optimization ({PSO}), and Artificial Bee Colony ({ABC}). This paper presents working of soft computing techniques and assessment of soft computing techniques to predict reliability. The parameter considered while estimating and prediction of reliability are also discussed. This study can be used in estimation and prediction of the reliability of various instruments used in the medical system, software engineering, computer engineering and mechanical engineering also. These concepts can be applied to both software and hardware, to predict the reliability using {CBSE}.},
  author       = {Diwaker, Chander and Tomar, Pradeep and Poonia, Ramesh and Singh, Vijander},
  date         = {2018},
  doi          = {10.1007/s10916-018-0952-3},
  file         = {Full Text:/Users/marcos/Zotero/storage/4MPQMDYA/Diwaker et al. - 2018 - Prediction of Software Reliability using Bio Inspi.pdf:application/pdf},
  issn         = {0148-5598},
  journaltitle = {Journal of Medical Systems},
  keywords     = {Genetic algorithm, Soft Computing, Software reliability, {CBSE}, {CBSR}, Optimization Technique, Software quality},
  number       = {5},
  pages        = {1--16},
  shortjournal = {J Med Syst},
  title        = {Prediction of Software Reliability using Bio Inspired Soft Computing Techniques},
  volume       = {42},
  bdsk-url-1   = {https://doi.org/10.1007/s10916-018-0952-3}
}

@article{felix_predicting_2020,
  abstract     = {Predicting the number of defects in software at the method level is important. However, little or no research has focused on method-level defect prediction. Therefore, considerable efforts are still required to demonstrate how method-level defect prediction can be achieved for a new software version. In the current study, we present an analysis of the relevant information obtained from the current version of a software product to construct regression models to predict the estimated number of defects in a new version using the variables of defect density, defect velocity and defect introduction time, which show considerable correlation with the number of method-level defects. These variables also show a mathematical relationship between defect density and defect acceleration at the method level, further indicating that the increase in the number of defects and the defect density are functions of the defect acceleration. We report an experiment conducted on the Finding Faults Using Ensemble...},
  author       = {Felix, Ebubeogu},
  date         = {2020},
  doi          = {10.1371/journal.pone.0229131},
  file         = {Full Text:/Users/marcos/Zotero/storage/28MZLVCK/Felix - 2020 - Predicting the number of defects in a new software.pdf:application/pdf},
  journaltitle = {{PLoS} One},
  keywords     = {Software, Computer Science, Source Code, Computer Programs, Defects, Correlation Coefficients, Datasets, Density, Entropy, Kuala Lumpur Malaysia, Malaysia, Regression Analysis, Regression Models, Software Quality, Studies, Velocity},
  number       = {3},
  pages        = {e0229131},
  title        = {Predicting the number of defects in a new software version},
  volume       = {15},
  bdsk-url-1   = {https://doi.org/10.1371/journal.pone.0229131}
}

@book{fenton1997software,
  title     = {Software Metrics: A Rigorous and Practical Approach},
  author    = {Fenton, N.E. and Pfleeger, S.L.},
  isbn      = {9780534954253},
  lccn      = {97134541},
  year      = {1997},
  publisher = {PWS Publishing Company}
}

@article{gao_effective_2017,
  abstract     = {Software has become ubiquitous in our daily lives, and with its increasing functionality and complexity comes a frequently tedious and prolonged debugging process. Of the three activities in program debugging (failure detection, fault localization, and bug fixing), the focus of this paper is on the first, failure detection, under the condition that there is no test oracle that can be used to automatically determine the success or failure of all the executions. More precisely, the outputs for many executions have to be verified manually, or the expected outputs are not even available. We want to determine whether there is a solution to help programmers predict the execution results. How good are these predicted results when they are used to help programmers find the locations of bugs? A framework is proposed to reduce the effort on output verification using a strategy based on the Hamming distance or K-Means clustering to predict results of test executions. Such data and the statement coverage...},
  author       = {Gao, Ruizhi and Wong, W and Chen, Zhenyu and Wang, Yabin},
  date         = {2017},
  doi          = {10.1007/s11219-015-9295-1},
  file         = {Full Text:/Users/marcos/Zotero/storage/66GZ8R23/Gao et al. - 2017 - Effective software fault localization using predic.pdf:application/pdf},
  issn         = {09639314},
  journaltitle = {Software Quality Journal},
  keywords     = {Software Engineering, Software Quality, Studies, Exam Score, Failure Analysis, Output Verification, Program Debugging, Software Fault Localization, Statement Suspiciousness, United States--Us},
  number       = {1},
  pages        = {131--169},
  title        = {Effective software fault localization using predicted execution results},
  volume       = {25},
  bdsk-url-1   = {https://doi.org/10.1007/s11219-015-9295-1}
}

@article{goues_automated_2019,
  abstract     = {Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.},
  author       = {Goues, Claire and Pradel, Michael and Roychoudhury, Abhik},
  date         = {2019},
  year         = {2019},
  doi          = {10.1145/3318162},
  file         = {Full Text:/Users/marcos/Zotero/storage/EYJF9KIX/Goues et al. - 2019 - Automated program repair.pdf:application/pdf},
  issn         = {00010782},
  journaltitle = {Communications of the {ACM}
},
  keywords     = {Computer Science, Engineering, Mathematics},
  number       = {12},
  pages        = {56--65},
  title        = {Automated program repair},
  volume       = {62},
  bdsk-url-1   = {https://doi.org/10.1145/3318162}
}

@inproceedings{gray2011misuse,
  title        = {The misuse of the NASA metrics data program data sets for automated software defect prediction},
  author       = {Gray, David and Bowes, David and Davey, Neil and Sun, Yi and Christianson, Bruce},
  booktitle    = {15th Annual Conference on Evaluation \& Assessment in Software Engineering (EASE 2011)},
  pages        = {96--103},
  year         = {2011},
  organization = {IET}
}

@article{Haghighi2018,
  doi       = {10.21105/joss.00729},
  url       = {https://doi.org/10.21105/joss.00729},
  year      = {2018},
  month     = {may},
  publisher = {The Open Journal},
  volume    = {3},
  number    = {25},
  pages     = {729},
  author    = {Sepand Haghighi and Masoomeh Jasemi and Shaahin Hessabi and Alireza Zolanvari},
  title     = {{PyCM}: Multiclass confusion matrix library in Python},
  journal   = {Journal of Open Source Software}
}

@book{halstead1977elements,
  title     = {Elements of software science},
  author    = {Halstead, Maurice Howard and others},
  volume    = {7},
  year      = {1977},
  publisher = {Elsevier New York}
}

@article{harikarthik_optimal_2019,
  abstract     = {Fault detection during testing can provide faster feedback on the system under test and permit software engineers begin correcting faults earlier. One application of prioritization technique involves regression testing for retesting of software following modifications. In this context, prioritization technique can take advantage of information gathered about the previous execution of test cases to obtain test case orderings. Test case prioritization techniques schedule test cases in an order that increases their effectiveness in meeting certain performance goals. Regression testing makes sure that up gradation of software in terms of adding new features or for bug fixing purposes should not hamper previously working functionalities. Whenever a software is upgraded or modified, a set of test cases are run on each of its functions to assure that the change to that function is not affecting other parts of the software that were previously running flawlessly.Our proposed regression test case...},
  author       = {Harikarthik, S. and Palanisamy, V. and Ramanathan, P.},
  date         = {2019},
  doi          = {10.1007/s10586-017-1401-7},
  file         = {Full Text:/Users/marcos/Zotero/storage/Z8I29HRT/Harikarthik et al. - 2019 - Optimal test suite selection in regression testing.pdf:application/pdf},
  issn         = {1386-7857},
  issue        = {Supplement 5},
  journaltitle = {Cluster Computing},
  keywords     = {Artificial neural network, Kernel fuzzy c-means clustering, Prioritization, Regression testing, Whale optimization},
  pages        = {11425--11434},
  shortjournal = {Cluster Comput},
  title        = {Optimal test suite selection in regression testing with testcase prioritization using modified Ann and Whale optimization algorithm},
  volume       = {22},
  bdsk-url-1   = {https://doi.org/10.1007/s10586-017-1401-7}
}

@article{jayanthi_software_2019,
  abstract     = {Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis ({PCA}) scheme which is further improved by incorporating maximum-likelihood...},
  author       = {Jayanthi, R. and Florence, Lilly},
  date         = {2019},
  doi          = {10.1007/s10586-018-1730-1},
  file         = {Full Text:/Users/marcos/Zotero/storage/M8WKKX5J/Jayanthi and Florence - 2019 - Software defect prediction techniques using metric.pdf:application/pdf},
  issn         = {1386-7857},
  issue        = {Supplement 1},
  journaltitle = {Cluster Computing},
  keywords     = {Defect prediction models, Machine learning techniques, Software defect prediction, Software metrics},
  pages        = {77--88},
  shortjournal = {Cluster Comput},
  title        = {Software defect prediction techniques using metrics based on neural network classifier},
  volume       = {22},
  bdsk-url-1   = {https://doi.org/10.1007/s10586-018-1730-1}
}

@article{kalsoom_dimensionality_2018,
  abstract     = {Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers---Bayes Net, {NB}, artificial neural network, support vector machines, K nearest neighbors, {AdaBoost}, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques---{SMOTE} and Resample with substitution are used to handle the class imbalance problem. We further used {FLDA}-based feature selection approach in combination with {SMOTE} and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from {PROMISE} repository. The proposed Resample-{FLDA} method gives better performance as compared to existing methods in terms of precision, recall, f -measure and area under the curve.},
  author       = {Kalsoom, Anum and Maqsood, Muazzam and Ghazanfar, Mustansar and Aadil, Farhan and Rho, Seungmin},
  date         = {2018},
  doi          = {10.1007/s11227-018-2326-5},
  file         = {Full Text:/Users/marcos/Zotero/storage/8IGJSGCZ/Kalsoom et al. - 2018 - A dimensionality reduction-based efficient softwar.pdf:application/pdf},
  issn         = {0920-8542},
  journaltitle = {The Journal of Supercomputing},
  keywords     = {Robustness, Software fault prediction, Fault-tolerance, Fisher linear discriminant, Reliability},
  number       = {9},
  pages        = {4568--4602},
  shortjournal = {J Supercomput},
  title        = {A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis ({FLDA})},
  volume       = {74},
  bdsk-url-1   = {https://doi.org/10.1007/s11227-018-2326-5}
}

@inproceedings{kim2011a,
  author    = {Kim, S. and Zhang, H. and Wu, R. and Gong, L.},
  date      = {2011},
  year      = {2011},
  title     = {Dealing with noise in defect prediction},
  volume    = {11},
  pages     = {481–490},
  language  = {en},
  booktitle = {Proceedings of the 33rd International Conference on Software Engineering, ACM},
  address   = {New York, NY, USA, ICSE}
}

@article{kirac_automatically_2019,
  abstract     = {We propose a novel technique based on recurrent artificial neural networks to generate test cases for black-box testing of reactive systems. We combine functional testing inputs that are automatically generated from a model together with manually-applied test cases for robustness testing. We use this combination to train a long short-term memory ({LSTM}) network. As a result, the network learns an implicit representation of the usage behavior that is liable to failures. We use this network to generate new event sequences as test cases. We applied our approach in the context of an industrial case study for the black-box testing of a digital {TV} system. {LSTM}-generated test cases were able to reveal several faults, including critical ones, that were not detected with existing automated or manual testing activities. Our approach is complementary to model-based and exploratory testing, and the combined approach outperforms random testing in terms of both fault coverage and execution time.},
  author       = {Kıra{\c c}, M. and Aktemur, Barı{\c s} and S{\"o}zer, Hasan and Gebizli, Ceren},
  date         = {2019},
  year         = {2019},
  doi          = {10.1007/s11219-018-9439-1},
  file         = {Full Text:/Users/marcos/Zotero/storage/CQDBMSJD/Kıra{\c c} et al. - 2019 - Automatically learning usage behavior and generati.pdf:application/pdf},
  issn         = {0963-9314},
  journaltitle = {Software Quality Journal},
  keywords     = {Test case generation, Black-box testing, Learning usage behavior, Long short-term memory networks, Recurrent neural networks},
  number       = {2},
  pages        = {861--883},
  shortjournal = {Software Qual J},
  title        = {Automatically learning usage behavior and generating event sequences for black-box testing of reactive systems},
  volume       = {27},
  bdsk-url-1   = {https://doi.org/10.1007/s11219-018-9439-1}
}

@article{kumaresan_software_2019,
  abstract     = {In growing Software industry, whenever engineers developed new software, they want to make sure that it is failure free and reliable. With the increasing reliability of hardware and growing complexity of software, the software reliability is a rising concern for both developer and users. Software reliability is the key part of quality and customer satisfaction. For the last three decades, many software reliability models have been successfully utilized in practical software reliability engineering. However, no single model can obtain the accurate prediction for all cases. This paper proposed the software reliability model with the increased number of training data set and neural networks. The back propagation algorithm has been chosen and applied for a learning process. The obtained results show that the proposed model increases the accuracy of the software reliability prediction.},
  author       = {Kumaresan, K. and Ganeshkumar, P.},
  date         = {2019},
  doi          = {10.1007/s10586-018-1942-4},
  file         = {Full Text:/Users/marcos/Zotero/storage/QKH8S739/Kumaresan and Ganeshkumar - 2019 - Software reliability modeling using increased fail.pdf:application/pdf},
  issn         = {1386-7857},
  issue        = {Supplement 2},
  journaltitle = {Cluster Computing},
  keywords     = {Failure prediction, Neural network, Software reliability, Software reliability prediction},
  pages        = {3095--3102},
  shortjournal = {Cluster Comput},
  title        = {Software reliability modeling using increased failure interval with {ANN}
},
  volume       = {22},
  bdsk-url-1   = {https://doi.org/10.1007/s10586-018-1942-4}
}

@article{mahajan_design_2015,
  abstract     = {During the previous years, the demand for producing the quality of software has been quickly increased. In this paper, Bayesian Regularization ({BR}) technique has been used for finding the software faults before the testing process. This technique helps us to reduce the cost of software testing which reduces the cost of the software project. The basic purpose of {BR} technique is to minimizes a combination of squared errors and weights, and then determine the correct combination so as to produce an efficient network.{BR} Technique algorithm based neural network tool is used for finding the results on the given public dataset. The accuracy of {BR} algorithm based neural network has been compared with Levenberg-Marquardt({LM}) algorithm and Back Propagation ({BPA}) algorithm for finding the software defects. Our results signify that the software fault prediction model using {BR} technique provide better accuracy than Levenberg-Marquardt ({LM}) algorithm and Back Propagation ({BPA}) algorithm....},
  author       = {Mahajan, Rohit and Gupta, Sunil Kumar and Bedi, Rajeev Kumar},
  date         = {2015},
  year         = {2015},
  doi          = {10.1016/j.procs.2015.02.154},
  file         = {Full Text:/Users/marcos/Zotero/storage/K29P5ZLX/Mahajan et al. - 2015 - Design of Software Fault Prediction Model Using BR.pdf:application/pdf},
  issn         = {1877-0509},
  issue        = {C},
  journaltitle = {Procedia computer science},
  keywords     = {Computer Science, Back Propagation (Bpa) Algorithm, Bayesian Regularization(Br)Algorithml, Levenberg-Marquardt (Lm)Algorithm, Neural Network, Public Dataset},
  pages        = {849--858},
  title        = {Design of Software Fault Prediction Model Using {BR} Technique},
  volume       = {46},
  bdsk-url-1   = {https://doi.org/10.1016/j.procs.2015.02.154}
}

@article{mccabe1976complexity,
  title     = {A complexity measure},
  author    = {McCabe, Thomas J},
  journal   = {IEEE Transactions on software Engineering},
  number    = {4},
  pages     = {308--320},
  year      = {1976},
  publisher = {IEEE}
}

@article{nembhard_towards_2019,
  abstract     = {Secure coding is crucial for the design of secure and efficient software and computing systems. However, many programmers avoid secure coding practices for a variety of reasons. Some of these reasons are lack of knowledge of secure coding standards, negligence, and poor performance of and usability issues with existing code analysis tools. Therefore, it is essential to create tools that address these issues and concerns. This article features the proposal, development, and evaluation of a recommender system that uses text mining techniques, coupled with {IntelliSense} technology, to recommend fixes for potential vulnerabilities in program code. The resulting system mines a large code base of over 1.6 million Java files using the {MapReduce} methodology, creating a knowledge base for a recommender system that provides fixes for taint-style vulnerabilities. Formative testing and a usability study determined that surveyed participants strongly believed that a recommender system would help programmers...},
  author       = {Nembhard, Fitzroy and Carvalho, Marco and Eskridge, Thomas},
  date         = {2019},
  doi          = {10.1186/s13635-019-0092-4},
  file         = {Full Text:/Users/marcos/Zotero/storage/V7VQANRU/Nembhard et al. - 2019 - Towards the application of recommender systems to .pdf:application/pdf},
  issn         = {16874161},
  journaltitle = {{EURASIP} Journal on Information Security},
  keywords     = {Software Engineering, Software Reliability, Data Mining, Java (Programming Language), Big Data, Code Analysis, Coding, Coding Standards, Intellisense, Knowledge Base, Knowledge Extraction, Negligence, Programmers, Recommender Systems, Secure Coding, Secure Systems, Taint, Usability, Vulnerability Detection},
  number       = {1},
  pages        = {1--24},
  title        = {Towards the application of recommender systems to secure coding},
  volume       = {2019},
  bdsk-url-1   = {https://doi.org/10.1186/s13635-019-0092-4}
}

@article{panda_slice-based_2016,
  abstract     = {Test case prioritization focuses on finding a suitable order of execution of the test cases in a test suite to meet some performance goals like detecting faults early. It is likely that some test cases execute the program parts that are more prone to errors and will detect more errors if executed early during the testing process. Finding an optimal order of execution for the selected regression test cases saves time and cost of retesting. This paper presents a static approach to prioritizing the test cases by computing the affected component coupling ({ACC}) of the affected parts of object-oriented programs. We construct a graph named affected slice graph ({ASG}) to represent these affected program parts. We determine the fault-proneness of the nodes of {ASG} by computing their respective {ACC} values. We assign higher priority to those test cases that cover the nodes with higher {ACC} values. Our analysis with mutation faults shows that the test cases executing the fault-prone program parts have...},
  author       = {Panda, S and Munjal, D and Mohapatra, D},
  date         = {2016},
  doi          = {10.1155/2016/7132404},
  file         = {Full Text:/Users/marcos/Zotero/storage/XRKTH7J9/Panda et al. - 2016 - A Slice-Based Change Impact Analysis for Regressio.pdf:application/pdf},
  issn         = {16878655},
  journaltitle = {Advances in Software Engineering},
  keywords     = {Mutation, Fehlerentdeckung, Lebenszyklus, Regressionsanalyse, Software-Entwicklung},
  title        = {A Slice-Based Change Impact Analysis for Regression Test Case Prioritization of Object-Oriented Programs},
  volume       = {2016},
  bdsk-url-1   = {https://doi.org/10.1155/2016/7132404}
}

@article{pena_modified_2020,
  abstract     = {Ransomware ({RW}) is a distinctive variety of malware that encrypts the files or locks the user's system by keeping and taking their files hostage, which leads to huge financial losses to users. In this article, we propose a new model that extracts the novel features from the {RW} dataset and performs classification of the {RW} and benign files. The proposed model can detect a large number of {RW} from various families at runtime and scan the network, registry activities, and file system throughout the execution. {API}-call series was reutilized to represent the behavior-based features of {RW}. The technique extracts fourteen-feature vector at runtime and analyzes it by applying online machine learning algorithms to predict the {RW}. To validate the effectiveness and scalability, we test 78550 recent malign and benign {RW} and compare with the random forest and {AdaBoost}, and the testing accuracy is extended at 99.56\%.},
  author       = {Ullah, Faizan and Javaid, Qaisar and Salam, Abdu and Ahmad, Masood and Sarwar, Nadeem and Shah, Dilawar and Abrar, Muhammad},
  date         = {2020},
  year         = {2020},
  doi          = {10.1155/2020/8845833},
  editor       = {Pe{\~n}a, Antonio},
  file         = {Full Text:/Users/marcos/Zotero/storage/JYPQAHY5/Ullah et al. - 2020 - Modified Decision Tree Technique for Ransomware De.pdf:application/pdf},
  issn         = {1058-9244},
  journaltitle = {Scientific Programming},
  keywords     = {Software, Internet, Algorithms, Machine Learning, Classification, Decision Trees, Computer Viruses, Digital Currencies, Electronic Mail Systems, Feature Extraction, Federal Bureau of Investigation--{FBI}, Malware, Ransomware},
  title        = {Modified Decision Tree Technique for Ransomware Detection at Runtime through {API} Calls},
  url          = {10.1155/2020/8845833},
  volume       = {2020},
  bdsk-url-1   = {10.1155/2020/8845833},
  bdsk-url-2   = {https://doi.org/10.1155/2020/8845833}
}

@article{planning2002economic,
  title   = {The economic impacts of inadequate infrastructure for software testing},
  author  = {Planning, Strategic},
  journal = {National Institute of Standards and Technology},
  year    = {2002}
}

@article{rani_neural_2018,
  abstract     = {This paper propose a learning algorithm of supervised back‐propagation neural networks for dynamic weighted combination of software reliability model. The proposed model is an assimilation of 3 well‐known non‐homogeneous poisson process ({NHPP})--based software reliability growth models with imperfect debugging. The novel approach of proposed supervised back propagation--based neural network 2‐stage architecture has a great impact on the network by combining the imperfect debugging models based on the nature of fault introduction rate during testing and debugging. Function approximation metrics are used for comparing the proposed model with individual models. Three data sets are trained using supervised back‐propagation neural networks to compare the performance and validity evaluation of proposed and existing {NHPP} models and dynamic weighted combinational model. Reliability analysis among important {NHPP} models incorporating imperfect debugging is illustrated through numerical and graphical explanation of several metrics using supervised back‐propagation neural networks. The novelty of this work is to give more attention on fault introduction rate in imperfect debugging during testing and debugging. It is a 2‐stage potential of new insight in {DWCM} approach in {ANN} in presence of backpropogation algorithm in software reliability fitting and modelling. This approach will eventually offer significant results than existing models.},
  author       = {Rani, Pooja and Mahapatra, G. S.},
  date         = {2018},
  doi          = {10.1002/stvr.1663},
  file         = {Full Text:/Users/marcos/Zotero/storage/C39J6692/Rani and Mahapatra - 2018 - Neural network for software reliability analysis o.pdf:application/pdf},
  issn         = {0960-0833},
  journaltitle = {Software Testing, Verification and Reliability},
  keywords     = {Neural Networks, Fault Introduction Rate, Imperfect Debugging, Non‐Homogenous Poisson Process, Software Reliability Growth Model, Supervised Back‐Propagation Algorithm},
  number       = {5},
  pages        = {n/a--n/a},
  title        = {Neural network for software reliability analysis of dynamically weighted {NHPP} growth models with imperfect debugging},
  volume       = {28},
  bdsk-url-1   = {https://doi.org/10.1002/stvr.1663}
}

@article{rathore_study_2019,
  abstract     = {Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed.},
  author       = {Rathore, Santosh and Kumar, Sandeep},
  date         = {2019},
  year         = {2019},
  doi          = {10.1007/s10462-017-9563-5},
  file         = {Full Text:/Users/marcos/Zotero/storage/BE5CNVAI/Rathore and Kumar - 2019 - A study on software fault prediction techniques.pdf:application/pdf},
  issn         = {0269-2821},
  journaltitle = {Artificial Intelligence Review},
  keywords     = {Software metrics, Fault prediction techniques, Software fault datasets, Software fault prediction, Taxonomic classification},
  number       = {2},
  pages        = {255--327},
  shortjournal = {Artif Intell Rev},
  title        = {A study on software fault prediction techniques},
  volume       = {51},
  bdsk-url-1   = {https://doi.org/10.1007/s10462-017-9563-5}
}

@article{roya_neuro-genetic_2015,
  abstract     = {In this paper, we propose a multi-layer feedforward artificial neural network ({ANN}) based logistic growth curve model ({LGCM}) for software reliability estimation and prediction. We develop the {ANN} by designing different activation functions for the hidden layer neurons of the network. We explain the {ANN} from the mathematical viewpoint of logistic growth curve modeling for software reliability. We also propose a neuro-genetic approach for the {ANN} based {LGCM} by optimizing the weights of the network using proposed genetic algorithm ({GA}). We first train the {ANN} using back-propagation algorithm ({BPA}) to predict software reliability. After that, we use the proposed {GA} to train the {ANN} by globally optimizing the weights of the network. The proposed {ANN} based {LGCM} is compared with the traditional Non-homogeneous Poisson process ({NHPP}) based software reliability growth models ({SRGMs}) and {ANN} based software reliability models. We present the comparison between the two training algorithms when they are applied to train the proposed {ANN} to predict software reliability. The applicability of the different approaches is explained through three real software failure data sets. Experimental results demonstrate that the proposed {ANN} based {LGCM} has better fitting and predictive capability than the other {NHPP} and {ANN} based software reliability models. It is also noted that when the proposed {GA} is employed as the learning algorithm to the {ANN}, the proposed {ANN} based {LGCM} gives more fitting and prediction accuracy i.e. the proposed neuro-genetic approach to the {LGCM} provides utmost predictive validity. Proposed model can be applied during software testing time to get better software reliability estimation and prediction than the other traditional {NHPP} and {ANN} based software reliability models.},
  author       = {Roya, Pratik and Mahapatrab, G and Deya, K},
  date         = {2015},
  doi          = {10.1016/j.eswa.2015.01.043},
  editor       = {Roya, Pratik},
  file         = {Full Text:/Users/marcos/Zotero/storage/FT3NQEZ6/Roya et al. - 2015 - Neuro-genetic approach on logistic model based sof.pdf:application/pdf},
  issn         = {0957-4174},
  journaltitle = {Expert Systems with Applications},
  keywords     = {Genetic Algorithms, Training, Genetic Algorithm, Algorithms, Software Reliability, Artificial Neural Network, Back-Propagation Algorithm, Learning Theory, Logistic Growth Curve Model, Mathematical Models, Networks, Neural Networks, Prediction, Robotics, Expert Systems, and Applications (Ci)},
  number       = {10},
  pages        = {4709--4718},
  title        = {Neuro-genetic approach on logistic model based software reliability prediction},
  url          = {10.1016/j.eswa.2015.01.043},
  volume       = {42},
  bdsk-url-1   = {10.1016/j.eswa.2015.01.043},
  bdsk-url-2   = {https://doi.org/10.1016/j.eswa.2015.01.043}
}

@article{ryu2016effective,
  title     = {Effective multi-objective na{\"\i}ve Bayes learning for cross-project defect prediction},
  author    = {Ryu, Duksan and Baik, Jongmoon},
  journal   = {Applied Soft Computing},
  volume    = {49},
  pages     = {1062--1077},
  year      = {2016},
  publisher = {Elsevier}
}

@misc{sasaki2007truth,
  title  = {The truth of the f-measure. 2007},
  author = {Sasaki, Yutaka and others},
  year   = {2007}
}

@misc{Sayyad-Shirabad+Menzies:2005,
  author       = {Sayyad Shirabad, J. and Menzies, T.J.},
  year         = {2005},
  title        = {{The {PROMISE} Repository of Software Engineering Databases.}},
  url          = {http://promise.site.uottawa.ca/SERepository},
  howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada}
}

@article{shamshiriRandomEvolutionarySearch2018,
  abstract     = {An important aim in software testing is constructing a test suite with high structural code coverage, that is, ensuring that most if not all of the code under test have been executed by the test cases comprising the test suite. Several search‐based techniques have proved successful at automatically generating tests that achieve high coverage. However, despite the well‐established arguments behind using evolutionary search algorithms (eg, genetic algorithms) in preference to random search, it remains an open question whether the benefits can actually be observed in practice when generating unit test suites for object‐oriented classes. In this paper, we report an empirical study on the effects of using evolutionary algorithms (including a genetic algorithm and chemical reaction optimization) to generate test suites, compared with generating test suites incrementally with random search. We apply the ES unit test suite generator to 1000 classes randomly selected from the SF110 corpus of open‐source projects. Surprisingly, the results show that the difference is much smaller than one might expect: While evolutionary search covers more branches of the type where standard fitness functions provide guidance, we observed that, in practice, the vast majority of branches do not provide any guidance to the search. These results suggest that, although evolutionary algorithms are more effective at covering complex branches, a random search may suffice to achieve high coverage of most object‐oriented classes. This paper reports an empirical study on the effects of using evolutionary algorithms to generate test suites, compared to generating test suites incrementally with random search. We show that although evolutionary algorithms are more effective at covering complex branches, a random search may suffice to achieve high coverage of most object‐oriented classes.},
  author       = {Shamshiri, Sina and Rojas, Jos{\'e} Miguel and Gazzola, Luca and Fraser, Gordon and Mcminn, Phil and Mariani, Leonardo and Arcuri, Andrea},
  date         = {2018},
  doi          = {10.1002/stvr.1660},
  file         = {/Users/marcos/Zotero/storage/9FEEBZV8/Shamshiri et al. - 2018 - Random or evolutionary search for object‐oriented .pdf},
  issn         = {0960-0833},
  journaltitle = {Software Testing, Verification and Reliability},
  keywords     = {Automated Software Testing,Automated Test Generation,Chemical Reaction Optimization,Genetic Algorithms,Random Search,Search‐Based Software Testing},
  number       = {4},
  pages        = {n/a--n/a},
  title        = {Random or Evolutionary Search for Object‐oriented Test Suite Generation?},
  volume       = {28},
  bdsk-url-1   = {https://doi.org/10.1002/stvr.1660}
}

@article{sharifipourStructuralTestData2018,
  abstract     = {Test data generation is one of the key activities that has a significant impact on the efficiency and effectiveness of software testing. Since manual test data generation is quite inefficient and even impractical, automated test data generation has been realized to produce an appropriate subset of input data to carry out effective software testing in reasonable times. This paper presents a memetic ant colony optimization (ACO) algorithm for structural test data generation. The proposed approach incorporates (1+1)-evolution strategies (ES) to improve the search functionality of ants in local moves and enhance search exploitation. Moreover, we have introduced a novel definition of the pheromone functionality in the way that it discourages ants from choosing mostly covered paths of the program to reinforce search exploration. Given that branch coverage is considered as the coverage criterion, two fitness functions are used accordingly for our proposed algorithm. The first fitness...},
  author       = {Sharifipour, Hossein and Shakeri, Mojtaba and Haghighi, Hassan},
  date         = {2018},
  doi          = {10.1016/j.swevo.2017.12.009},
  file         = {/Users/marcos/Zotero/storage/SAGH9Z3U/Sharifipour et al. - 2018 - Structural test data generation using a memetic an.pdf},
  issn         = {2210-6502},
  journaltitle = {Swarm and Evolutionary Computation},
  keywords     = {Ant Colony Optimization,Automated Test Data Generation,Branch Coverage,Computer Science,Evolution Strategies,Fitness Functions,Pheromone Trail},
  pages        = {76--91},
  title        = {Structural Test Data Generation Using a Memetic Ant Colony Optimization Based on Evolution Strategies},
  volume       = {40},
  bdsk-url-1   = {https://doi.org/10.1016/j.swevo.2017.12.009}
}

@article{shepperdDataQualityComments2013,
  ids          = {shepperdDataQualityComments2013a},
  title        = {Data Quality: Some Comments on the {{NASA}} Software Defect Datasets},
  author       = {Shepperd, M. and Song, Q. and Sun, Z. and Mair, C.},
  date         = {2013},
  journaltitle = {IEEE Transactions on Software Engineering},
  volume       = {39},
  pages        = {1208--1215},
  doi          = {10.1109/tse.2013.11},
  file         = {/Users/marcos/Zotero/storage/7KSDD52Y/Shepperd et al. - 2013 - Data quality some comments on the NASA software d.pdf;/Users/marcos/Zotero/storage/JR4H6RUT/Shepperd et al. - 2013 - Data quality some comments on the nasa software d.pdf},
  langid       = {english},
  number       = {9}
}


@article{tianTestDataGeneration2016,
  abstract     = {Employing genetic algorithms to generate test data for path coverage has been an important method in software testing. Previous work, however, is suitable mainly for serial programs. Automatic test data generation for path coverage of message-passing parallel programs without non-determinacy is investigated in this study by using co-evolutionary genetic algorithms. This problem is first formulated as a single-objective optimization problem, and then a novel co-evolutionary genetic algorithm is proposed to tackle the formulated optimization problem. This method employs the alternate co-evolution of two kinds of populations to generate test data that meet path coverage. The proposed method is applied to seven parallel programs, and compared with the other three methods. The experimental results show that the proposed method has the best success rate and the least number of evaluated individuals and time consumption.},
  author       = {Tian, Tian and Gong, Dunwei},
  date         = {2016},
  doi          = {10.1007/s10515-014-0173-z},
  file         = {/Users/marcos/Zotero/storage/85LLBZLJ/Tian and Gong - 2016 - Test data generation for path coverage of message-.pdf},
  issn         = {0928-8910},
  journaltitle = {Autom Softw Eng},
  keywords     = {Co-evolutionary genetic algorithm,Parallel program,Path coverage,Software testing,Test data},
  number       = {3},
  pages        = {469--500},
  title        = {Test Data Generation for Path Coverage of Message-Passing Parallel Programs Based on Co-Evolutionary Genetic Algorithms},
  volume       = {23},
  bdsk-url-1   = {https://doi.org/10.1007/s10515-014-0173-z}
}

@article{varma2000automated,
  title     = {Automated software testing: introduction, management and performance},
  author    = {Varma, Tathagat},
  journal   = {ACM SIGSOFT Software Engineering Notes},
  volume    = {25},
  number    = {3},
  pages     = {65--65},
  year      = {2000},
  publisher = {ACM New York, NY, USA}
}

@article{varshneyHybridParticleSwarm2018,
  author       = {Varshney, S. and Mehrotra, M.},
  date         = {2018},
  doi          = {10.31449/inf.v42i3.1497},
  file         = {/Users/marcos/Zotero/storage/TC8DJMGF/Varshney and Mehrotra - 2018 - A hybrid particle swarm optimization and different.pdf},
  issn         = {03505596},
  journaltitle = {Informatica (Ljubljana)},
  keywords     = {Data Flow Testing,Differential Evolution,Dominance Tree,Particle Swarm Optimization,Search Based Software Testing},
  number       = {3},
  pages        = {417--438},
  title        = {A Hybrid Particle Swarm Optimization and Differential Evolution Based Test Data Generation Algorithm for Data-Flow Coverage Using Neighbourhood Search Strategy},
  volume       = {42},
  bdsk-url-1   = {https://doi.org/10.31449/inf.v42i3.1497}
}

@article{vitiello_software_2019,
  abstract     = {In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network ({DP}-{ARNN}). More specifically, {DP}-{ARNN} first parses abstract syntax trees ({ASTs}) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of {DP}-{ARNN} by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it...},
  author       = {Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Kang, Yang and Chen, Liqiong},
  date         = {2019},
  doi          = {10.1155/2019/6230953},
  editor       = {Vitiello, Autilia},
  file         = {Full Text:/Users/marcos/Zotero/storage/RHV98H32/Fan et al. - 2019 - Software Defect Prediction via Attention-Based Rec.pdf:application/pdf},
  issn         = {1058-9244},
  journaltitle = {Scientific Programming},
  keywords     = {Artificial Intelligence, Semantics, Software Engineering, Source Code, Software Reliability, Neural Networks, Machine Learning, Classification, Data Mining, Defects, Dictionaries, Identification Methods, Java (Programming Language), Mapping, Network Reliability, Recurrent Neural Networks, Research, Teaching Methods},
  title        = {Software Defect Prediction via Attention-Based Recurrent Neural Network},
  volume       = {2019},
  bdsk-url-1   = {https://doi.org/10.1155/2019/6230953}
}

@article{yaoConstrainedMultiobjectiveTest2015,
  abstract     = {A crucial task of software testing is the generation of high-quality test data, so as to find defects and errors during various periods of software development. However, existing coverage-based testing methods seldom consider the fault finding ability of the test data. This paper establishes a constrained multi-objective model of test data generation, so that the generated test suite has better spatial distribution on the basis of satisfying statement coverage criterion, and thereby enhance its error detection ability. In addition, the authors propose a genetic algorithm (GA) based on set evolution to solve the model. The experimental results show that the test data generated by the proposed model have higher fault finding ability than statement coverage testing and adaptive random testing},
  author       = {Yao, Xiangjuan and Gong, Dunwei and Zhang, Gongjie},
  date         = {2015},
  doi          = {10.1049/iet-sen.2014.0058},
  editor       = {Yao, Xiangjuan},
  file         = {/Users/marcos/Zotero/storage/25ND3HQC/Yao et al. - 2015 - Constrained multi-objective test data generation b.pdf},
  issn         = {1751-8806},
  journaltitle = {IET Software},
  keywords     = {(An),Algorithms,Computer Programs,Constrained Multiobjective Test Data Generation,Constraints,Electronics and Communications Milieux (General) (Ea),Error Detection,Error Detection Ability,Faults,Genetic Algorithms,Program Testing,Random Processes,Software Development,Software Engineering (General) (Ci),Software Testing,Spatial Distribution,Statement Coverage Criterion,Statement Coverage Testing},
  number       = {4},
  pages        = {103--108},
  title        = {Constrained Multi-Objective Test Data Generation Based on Set Evolution},
  volume       = {9},
  bdsk-url-1   = {https://doi.org/10.1049/iet-sen.2014.0058}
}

@article{zhang_machine_2020,
  abstract     = {This paper provides a comprehensive survey of Machine Learning Testing ({ML} testing) research. It covers 138 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in machine learning testing.},
  author       = {Zhang, Jie M and Harman, Mark and Ma, Lei and Liu, Yang},
  date         = {2020},
  doi          = {10.1109/TSE.2019.2962027},
  file         = {Submitted Version:/Users/marcos/Zotero/storage/NBXRG3QN/Zhang et al. - 2020 - Machine Learning Testing Survey, Landscapes and H.pdf:application/pdf},
  issn         = {0098-5589},
  journaltitle = {{IEEE} transactions on software engineering},
  keywords     = {Software Testing, Computer Science, Software Engineering, Data Models, Deep Neural Network, Machine Learning, Robustness, Training Data},
  pages        = {1--1},
  title        = {Machine Learning Testing: Survey, Landscapes and Horizons},
  url          = {10.1109/TSE.2019.2962027},
  bdsk-url-1   = {10.1109/TSE.2019.2962027},
  bdsk-url-2   = {https://doi.org/10.1109/TSE.2019.2962027}
}